/* 
 * File:   NetworkConfiguration.h
 * Author: Jan Vojt
 *
 * Created on June 5, 2014, 8:16 PM
 */

#ifndef NETWORKCONFIGURATION_H
#define	NETWORKCONFIGURATION_H

#include <cstdlib>
#include <string>
#include "../common.h"

using namespace std;

class NetworkConfiguration {
public:
    NetworkConfiguration();
    NetworkConfiguration(const NetworkConfiguration& orig);
    virtual ~NetworkConfiguration();
    // Returns number of layers in the network
    // including input and output layer.
    int getLayers();
    void setLayers(int layers);
    // Returns number of neurons indexed from zero.
    int getNeurons(int layer);
    // Sets number of neurons in given layer, layer being indexed from zero.
    void setNeurons(int layer, int neurons);
    // Enables or disables network bias.
    void setBias(bool enabled);
    // Returns whether bias is enabled.
    bool getBias();
    // Gets the minimum value generated by random generator
    // when initializing network weights.
    data_t getInitMin();
    void setInitMin(data_t min);
    // Gets the maximum value generated by random generator
    // when initializing network weights.
    data_t getInitMax();
    void setInitMax(data_t max);
    // Parse and set the interval for weight initialization.
    void parseInitInterval(const char *intervalConf);
    // Parse layer configuration from comma separated list of neuron counts.
    void parseLayerConf(char *layerConf);
    
    string getLayerType(int layerIndex);
    
    string getLayersConf(int layerIndex);
    
    /**
     * Gets the path to a configuration file used, or a comma-separated list of
     * number of neurons in each respective layer of fully-connected network.
     * The purpose is to simplify logging, so that the string does not
     * need to be rebuilt.
     * 
     * @return source of network layer configuration
     */
    char *getConfSource();
    
    data_t getLearningRate();
    
    void setLearningRate(data_t learningRate);
    
    // Pointer to activation function normalizing the neurons potential.
    // Input potential is preserved and the normalized value
    // is put into the target array. It is also possible to provide
    // the same pointer for input and target for in-place computation
    // saving some memory.
    void (*activationFnc)(data_t *x, data_t *y, int layerSize);
    // Derivative of activation function.
    void (*dActivationFnc)(data_t *x, data_t *y, int layerSize);
private:
    void initConf();
    
    /**
     * Parse and set the interval for weight and bias initialization.
     * 
     * @param intervalConf comma-separated interval
     * @param format format of parsed number
     */
    void parseInitInterval(const char *intervalConf, const char *format);
    
    void parseFromString(char *layerConf);
    
    void parseFromFile(char *layerConf);
    
    /** Number of layers in a network. */
    int layers;
    
    /** Layers in network. */
    std::string **layersConf = NULL;
    
    // number of neurons in each network layer
    int *neuronConf;
    // flag determining whether the network uses bias, true by default
    bool bias;
    // Minimum value generated by random generator
    // when initializing network weights.
    data_t initMin;
    // Maximum value generated by random generator
    // when initializing network weights.
    data_t initMax;
    
    /**
     * Source of the network layer configuration.
     * May be a comma-separated list of neurons per layer for fully-connected
     * network, or a path to configuration file.
     */
    char *confSource = NULL;
    
    /** Learning rate used in backpropagation. */
    data_t learningRate = 1;
};

#endif	/* NETWORKCONFIGURATION_H */

